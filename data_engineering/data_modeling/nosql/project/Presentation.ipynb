{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Modeling with Apache Cassandra\n",
    "\n",
    "The following notebook is an adaptation of the initial template that was supplied.  Deviations from the initial notebook will be noted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import main\n",
    "import cql\n",
    "import config\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Part 1 - Pre-processing\n",
    "\n",
    "In the initial notebook, pre-processing was done over several steps:\n",
    "\n",
    "1. Creating a list of files from a filepath\n",
    "2. Iterating over each file and appending each row to a list\n",
    "3. Create larger csv file from created list\n",
    "\n",
    "The new adaptation does the following:\n",
    "\n",
    "1. Construct a file directory where files reside\n",
    "2. Create list of files from the file directory\n",
    "3. Construct a pandas dataframe from the list of files\n",
    "\n",
    "The code below (without docstrings) is taken out of `main.py` and shows the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_file_directory(filepath):\n",
    "    cwd = os.getcwd()\n",
    "    cwd += filepath\n",
    "    return cwd\n",
    "\n",
    "def get_files(file_directory, format=\"csv\"):\n",
    "    return glob.glob(file_directory + f\"/*.{format}\")\n",
    "\n",
    "\n",
    "def construct_dataframe_from_files(files):\n",
    "    df = pd.concat((pd.read_csv(f) for f in files))\n",
    "    df.dropna(subset=['artist'], inplace=True)\n",
    "    df[['itemInSession', 'sessionId', 'userId']] = \\\n",
    "        df[['itemInSession', 'sessionId', 'userId']].apply(\n",
    "            pd.to_numeric, downcast='integer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The code above is utilized inside a `run` function.  The `run` function is passed a filepath from an argument from the command line or, if nothing is provided, it will default to `/event_data`.  The first part of the function is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_directory = get_file_directory('/event_data')\n",
    "files = get_files(file_directory)\n",
    "dataframe = construct_dataframe_from_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6820 rows in the dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Fine Frenzy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Anabelle</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Simpson</td>\n",
       "      <td>267.91138</td>\n",
       "      <td>free</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541040e+12</td>\n",
       "      <td>256</td>\n",
       "      <td>Almost Lover (Album Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nirvana</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>214.77832</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>Serve The Servants</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Television</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>238.49751</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>See No Evil  (Remastered LP Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOHN COLTRANE</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>346.43546</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>Blues To Bechet (LP Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOFX</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>80.79628</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>It's My Job To Keep Punk Rock Elite</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "0  A Fine Frenzy  Logged In  Anabelle      F              0  Simpson   \n",
       "1        Nirvana  Logged In    Aleena      F              0    Kirby   \n",
       "2     Television  Logged In    Aleena      F              1    Kirby   \n",
       "3  JOHN COLTRANE  Logged In    Aleena      F              2    Kirby   \n",
       "4           NOFX  Logged In    Aleena      F              3    Kirby   \n",
       "\n",
       "      length level                                     location method  \\\n",
       "0  267.91138  free  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD    PUT   \n",
       "1  214.77832  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "2  238.49751  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "3  346.43546  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "4   80.79628  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "\n",
       "       page  registration  sessionId                                  song  \\\n",
       "0  NextSong  1.541040e+12        256          Almost Lover (Album Version)   \n",
       "1  NextSong  1.541020e+12        237                    Serve The Servants   \n",
       "2  NextSong  1.541020e+12        237  See No Evil  (Remastered LP Version)   \n",
       "3  NextSong  1.541020e+12        237          Blues To Bechet (LP Version)   \n",
       "4  NextSong  1.541020e+12        237   It's My Job To Keep Punk Rock Elite   \n",
       "\n",
       "   status            ts  userId  \n",
       "0     200  1.541380e+12      69  \n",
       "1     200  1.541380e+12      44  \n",
       "2     200  1.541380e+12      44  \n",
       "3     200  1.541380e+12      44  \n",
       "4     200  1.541380e+12      44  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are {} rows in the dataframe\".format(len(dataframe)))\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Part of the project's requirements is to create an event_data_new.csv file.  I won't use this for my ETL process, but the code below will create the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv('event_datafile_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Part 2 - Apache Cassandra\n",
    "\n",
    "The second part of the project is to create tables and insert data into an Apache Cassandra Cluster.  In an effort to reduce code duplication, I created two classes:  `Cassandra` and `ETL`.  Cassandra functions as my connection to the Cluster and is the base object in the ETL class.  ETL functions as my means to execute queries (CREATE and INSERT).  ETL relies on a dictionary, which can be found in the `config.py` file, as well as a dataframe, which serves as the data to be inserted into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.Cluster at 0x7f241e1b3ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.Session at 0x7f241e16f6d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'item': {'table': 'item_detail',\n",
       "  'columns': ['sessionId', 'itemInSession', 'artist', 'song', 'length'],\n",
       "  'column_types': ['int', 'int', 'text', 'text', 'float'],\n",
       "  'primary_key': ['sessionId', 'itemInSession'],\n",
       "  'primary_key_description': '\\n            The item_detail table uses a compound primary key with two components:\\n            sessionId and itemInSession.  The sessionId will be how the data\\n            is partitioned in the cluster and itemInSession will (1)\\n            enforce uniqueness on the row and (2) order the data in ascending\\n            order.  The query used for this table is concerned with a specific\\n            item in a session so it made sense to me to partition the data by\\n            session.\\n        '},\n",
       " 'session': {'table': 'session_detail',\n",
       "  'columns': ['sessionId',\n",
       "   'itemInSession',\n",
       "   'artist',\n",
       "   'song',\n",
       "   'userId',\n",
       "   'firstName',\n",
       "   'lastName'],\n",
       "  'column_types': ['int', 'int', 'text', 'text', 'int', 'text', 'text'],\n",
       "  'primary_key': ['userId', 'sessionId', 'itemInSession'],\n",
       "  'primary_key_description': '\\n            The session_detail table uses a compound primary key with three\\n            components:  userId, sessionId, and itemInSession.  The userId will\\n            be how the data is partitioned in the cluster and sessionId and\\n            itemInSession will (1) enforce uniqueness on the row and (2) order\\n            the data in ascending order.  The query used for this table is\\n            concerned with a specific user and session so it made sense to me\\n            to partition the data by user.\\n        '},\n",
       " 'song': {'table': 'song_detail',\n",
       "  'columns': ['sessionId', 'itemInSession', 'song', 'firstName', 'lastName'],\n",
       "  'column_types': ['int', 'int', 'text', 'text', 'text'],\n",
       "  'primary_key': ['song', 'sessionId', 'itemInSession'],\n",
       "  'primary_key_description': '\\n            The song_detail table uses a compound primary key with three\\n            components:  song, sessionId, and itemInSession.  The song will\\n            be how the data is partitioned in the cluster and sessionId and\\n            itemInSession will (1) enforce uniqueness on the row and (2) order\\n            the data in ascending order.  The query used for this table is\\n            concerned with a specific song so it made sense to me\\n            to partition the data by song.\\n        '}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Fine Frenzy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Anabelle</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Simpson</td>\n",
       "      <td>267.91138</td>\n",
       "      <td>free</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541040e+12</td>\n",
       "      <td>256</td>\n",
       "      <td>Almost Lover (Album Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nirvana</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>214.77832</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>Serve The Servants</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Television</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>238.49751</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>See No Evil  (Remastered LP Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOHN COLTRANE</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>346.43546</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>Blues To Bechet (LP Version)</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOFX</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Aleena</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>80.79628</td>\n",
       "      <td>paid</td>\n",
       "      <td>Waterloo-Cedar Falls, IA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541020e+12</td>\n",
       "      <td>237</td>\n",
       "      <td>It's My Job To Keep Punk Rock Elite</td>\n",
       "      <td>200</td>\n",
       "      <td>1.541380e+12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist       auth firstName gender  itemInSession lastName  \\\n",
       "0  A Fine Frenzy  Logged In  Anabelle      F              0  Simpson   \n",
       "1        Nirvana  Logged In    Aleena      F              0    Kirby   \n",
       "2     Television  Logged In    Aleena      F              1    Kirby   \n",
       "3  JOHN COLTRANE  Logged In    Aleena      F              2    Kirby   \n",
       "4           NOFX  Logged In    Aleena      F              3    Kirby   \n",
       "\n",
       "      length level                                     location method  \\\n",
       "0  267.91138  free  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD    PUT   \n",
       "1  214.77832  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "2  238.49751  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "3  346.43546  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "4   80.79628  paid                     Waterloo-Cedar Falls, IA    PUT   \n",
       "\n",
       "       page  registration  sessionId                                  song  \\\n",
       "0  NextSong  1.541040e+12        256          Almost Lover (Album Version)   \n",
       "1  NextSong  1.541020e+12        237                    Serve The Servants   \n",
       "2  NextSong  1.541020e+12        237  See No Evil  (Remastered LP Version)   \n",
       "3  NextSong  1.541020e+12        237          Blues To Bechet (LP Version)   \n",
       "4  NextSong  1.541020e+12        237   It's My Job To Keep Punk Rock Elite   \n",
       "\n",
       "   status            ts  userId  \n",
       "0     200  1.541380e+12      69  \n",
       "1     200  1.541380e+12      44  \n",
       "2     200  1.541380e+12      44  \n",
       "3     200  1.541380e+12      44  \n",
       "4     200  1.541380e+12      44  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ETL class\n",
    "etl = cql.ETL(config.sparkify_dictionary, dataframe)\n",
    "\n",
    "# Inspect Class\n",
    "etl.cluster\n",
    "etl.session\n",
    "etl.dictionary\n",
    "etl.dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The ETL class also has attributes that are accessed when given a key of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Columns for item'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['sessionId', 'itemInSession', 'artist', 'song', 'length']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['int', 'int', 'text', 'text', 'float']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'%s, %s, %s, %s, %s'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['sessionId', 'itemInSession']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n            CREATE TABLE IF NOT EXISTS item_detail\\n            (sessionId int, itemInSession int, artist text, song text, length float,\\n            PRIMARY KEY (\\n                sessionId, itemInSession))\\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n            INSERT INTO item_detail\\n            (sessionId, itemInSession, artist, song, length)\\n            VALUES (%s, %s, %s, %s, %s)\\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = list(etl.dictionary.keys())[0]\n",
    "f\"Columns for {key}\"\n",
    "etl._columns(key)\n",
    "etl._column_types(key)\n",
    "etl._column_placeholders(key)\n",
    "etl._primary_key(key)\n",
    "etl._create_statement(key)\n",
    "etl._insert_statement(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The main access point into the `ETL` class is through the `run` method.  This method will take care of creating the table (if it doesn't exist) and then inserting the appropriate data.\n",
    "\n",
    "### Important Caveat\n",
    "The columns specified in the dictionary need to be the **EXACT SAME** as what's in the supplied dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for item_detail inserted\n",
      "Primary Key rationale for item_detail:\n",
      "\n",
      "            The item_detail table uses a compound primary key with two components:\n",
      "            sessionId and itemInSession.  The sessionId will be how the data\n",
      "            is partitioned in the cluster and itemInSession will (1)\n",
      "            enforce uniqueness on the row and (2) order the data in ascending\n",
      "            order.  The query used for this table is concerned with a specific\n",
      "            item in a session so it made sense to me to partition the data by\n",
      "            session.\n",
      "        \n",
      "Data for session_detail inserted\n",
      "Primary Key rationale for session_detail:\n",
      "\n",
      "            The session_detail table uses a compound primary key with three\n",
      "            components:  userId, sessionId, and itemInSession.  The userId will\n",
      "            be how the data is partitioned in the cluster and sessionId and\n",
      "            itemInSession will (1) enforce uniqueness on the row and (2) order\n",
      "            the data in ascending order.  The query used for this table is\n",
      "            concerned with a specific user and session so it made sense to me\n",
      "            to partition the data by user.\n",
      "        \n",
      "Data for song_detail inserted\n",
      "Primary Key rationale for song_detail:\n",
      "\n",
      "            The song_detail table uses a compound primary key with three\n",
      "            components:  song, sessionId, and itemInSession.  The song will\n",
      "            be how the data is partitioned in the cluster and sessionId and\n",
      "            itemInSession will (1) enforce uniqueness on the row and (2) order\n",
      "            the data in ascending order.  The query used for this table is\n",
      "            concerned with a specific song so it made sense to me\n",
      "            to partition the data by song.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "for key in etl.dictionary.keys():\n",
    "    etl.run(key)\n",
    "    print(f\"Data for {etl._table(key)} inserted\")\n",
    "    print(f\"Primary Key rationale for {etl._table(key)}:\")\n",
    "    print(etl.dictionary[key]['primary_key_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from item_detail\n",
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=495.30731201171875)\n",
      "Data from session_detail\n",
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n",
      "Data from song_detail\n",
      "Row(firstname='Sara', lastname='Johnson')\n",
      "Row(firstname='Jacqueline', lastname='Lynch')\n",
      "Row(firstname='Tegan', lastname='Levine')\n"
     ]
    }
   ],
   "source": [
    "# Verify data has been inserted into the database\n",
    "item_detail_query = \"SELECT artist, song, length FROM item_detail WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "session_detail_query = \"SELECT artist, song, firstName, lastName FROM session_detail WHERE userId = 10 AND sessionId = 182\"\n",
    "song_detail_query = \"SELECT firstName, lastName FROM song_detail WHERE song = 'All Hands Against His Own'\"\n",
    "queries = [item_detail_query, session_detail_query, song_detail_query]\n",
    "for query in queries:\n",
    "    rows = etl.session.execute(query)\n",
    "    table = re.search('FROM (.+?) WHERE', query)\n",
    "    print(\"Data from {}\".format(table.group(1)))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f241cfe9898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f241e056be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f241e05a400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop tables before closing out session\n",
    "tables = [etl.dictionary[key]['table'] for key in etl.dictionary.keys()]\n",
    "\n",
    "for table in tables:\n",
    "    try:\n",
    "        query = f'drop table if exists {table}'\n",
    "        etl.session.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Shutdown session and cluster\n",
    "etl.session.shutdown()\n",
    "etl.cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
